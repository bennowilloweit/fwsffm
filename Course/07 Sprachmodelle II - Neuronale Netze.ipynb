{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c7ac81-8700-4030-b069-e87a94162c4c",
   "metadata": {},
   "source": [
    "# Sprachmodelle II - Neuronale Netze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447464a9-4b64-4626-a59a-fd74e6d44205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = \"{:,.4f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13330bf6-884c-43ce-b65a-a8b8350d9668",
   "metadata": {},
   "source": [
    "Wir ladene einen ersten Text aus einer Datei und geben ihn aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce39ed2-78eb-4dd6-9f4f-3e4101872f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('txt/zauberlehrling.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa025844-808b-4983-b231-d295d389bdfe",
   "metadata": {},
   "source": [
    "### Einstieg & Recap\n",
    "\n",
    "Wieder machen wir den Computer bekannt mit den allen Texten, die er beherrschen soll. Dazu erzeugen wir einen Tokenizer und füttern ihn mit dem Gedicht 'Der Zauberlehrling'. Der Tokenizer zerlegt das Gedicht in Token und merkt sich, welche Token vorkamen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05c15d-12c8-4f90-845c-ff5049286fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fws.tokenizer import FWSTokenizer\n",
    "tokenizer = FWSTokenizer(text)\n",
    "toks = tokenizer.tokenize(text)\n",
    "df = pd.DataFrame(\n",
    "    data={'token':tokenizer.vocab_str(), 'output':tokenizer.decode_list(tokenizer.vocab_int())}, \n",
    "    index=tokenizer.vocab_int())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd29d6-9fc2-4259-951a-fe8b603b4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Anzahl der Token: {len(toks)}\")\n",
    "print(f\"Anzahl der unterschiedlichen Token: {tokenizer.vsize}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9da45-4117-4816-8191-9d491664435d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Aufgabe 1\n",
    "\n",
    "##### 0,5 + 0,5 Punkte\n",
    "\n",
    "- F: Was ist ein Token?\n",
    "- A:\n",
    "- F: Warum ist die Anzahl der unterschiedlichen Token kleiner als die Anzahl der Token?\n",
    "- A:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e12f7ce-1909-4e6f-b789-504592a9b61c",
   "metadata": {},
   "source": [
    "### Text zu Zahlen in einer Tabelle\n",
    "\n",
    "Wir erinnern uns, dass Machine Learning Modelle grundsätzlich nur Zahlen ausgeben und auch nur Zahlen als Eingabe akzeptieren. Wir wissen, dass wir mit dem Tokenizer aus Text Zahlen und aus Zahlen Text machen können. Wir schauen uns zunächst an, wie die Eingabedaten für unser erstes Machine Learning Modell aussahen. Auf Basis dieser Daten hat das Modell gelernt, bei welcher Temperatur wie viel Eis verkauft wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d93c9-d8a0-4775-9383-ad085b78d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/eis.csv')\n",
    "df[[\"Temperatur\", \"Eis\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429e39e-1979-42db-b175-d85c45f8ce95",
   "metadata": {},
   "source": [
    "Mit Hilfe des Tokenizers erzeugen wir uns aus dem Text 'Der Zauberlehrling' eine Tabelle mit Trainingsadten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550b2df-679a-4c30-9ee5-774edcd3224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for t1, t2 in zip(toks, toks[1:]):\n",
    "    ix1 = tokenizer.idx(t1)\n",
    "    ix2 = tokenizer.idx(t2)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "xsl = xs.tolist()\n",
    "ysl = ys.tolist()\n",
    "\n",
    "data = {\"xs\": xsl, \"ys\": ysl, \"xs_dec\": tokenizer.decode_list(xsl), \"ys_dec\": tokenizer.decode_list(ysl)}\n",
    "df = pd.DataFrame.from_dict(data, orient='index').transpose()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b55a2b-6179-404a-a607-472251736d2e",
   "metadata": {},
   "source": [
    "#### Aufgabe 2\n",
    "\n",
    "##### 2 + 1 Punkte\n",
    "\n",
    "Oben sehen Sie die ersten Zeilen der Tabelle mit den Trainingsdaten aus dem Gedicht. \n",
    "\n",
    "- F: Finden Sie jeweils einen besseren Namen für die Spalten 'xs' und 'ys'. \n",
    "- A:\n",
    "- F: In der Tabelle Steckt das ganze Gedicht. Wie viele Zeilen hat die Tabelle?\n",
    "- A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1721d6-4413-4792-88eb-1086e00ac309",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((tokenizer.vsize, tokenizer.vsize), requires_grad=True)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1abc941-0db0-4194-88d0-25c5b342d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68755d-4980-40cd-a6be-e342b5edac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(A, max_tokens, start_token_id):\n",
    "    gen_idx_seq = [start_token_id]\n",
    "    while True:\n",
    "        logits = A[gen_idx_seq[-1]]\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum() \n",
    "        idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        gen_idx_seq.append(idx)\n",
    "        if len(gen_idx_seq) == max_tokens:\n",
    "            break\n",
    "    \n",
    "    return gen_idx_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e9f98-5140-4a94-b13f-fb72685838f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 32\n",
    "start = tokenizer.idx('<NL>')\n",
    "\n",
    "id_seq = generate(W, tokens, start)\n",
    "print(id_seq)\n",
    "print(tokenizer.decode(id_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26e55d-665d-44c1-8a26-78a7cb9f58de",
   "metadata": {},
   "source": [
    "#### Aufgabe 3\n",
    "\n",
    "##### 1 + 2 + 1 + 2 = 6 Punkte\n",
    "\n",
    "- F: Wie Punkte (Pixel) hat das Bild oben? \n",
    "- A:\n",
    "- F: Führen Sie die Zelle oberhalb mehrfach aus. Was wird hier ausgegeben?\n",
    "- A:\n",
    "- F: Warum ändert sich die Ausgabe bei jedem Versuch?\n",
    "- A:\n",
    "- F: Was sieht man auf dem Bild oben?\n",
    "- A:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d73ba4-fdb0-4563-a31d-9d09ee3498b9",
   "metadata": {},
   "source": [
    "### Der Lernprozess\n",
    "\n",
    "Wie in unseren ersten Beispielen mit dem Eisstand, trainieren wir unser Modell jetzt schrittweise indem wir die Parameter schrittweise so verändern, dass der Fehler möglichst schnell kleiner wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b34abe-a66c-4042-b72c-7ddda266271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(W, xs, ys, learning_rate, v_size):\n",
    "    xenc = F.one_hot(xs, num_classes=v_size).float()\n",
    "    logits = xenc @ W \n",
    "    counts = logits.exp() \n",
    "    probs = counts / counts.sum(1, keepdim=True) #normalize rows\n",
    "    loss = -probs[torch.arange(xs.shape[0]), ys].log().mean() + learning_rate * (W**2).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e831706f-267e-439c-93a7-da2b2a16f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(passes, learning_rate, prints=4):\n",
    "    s = passes / prints\n",
    "    r = 2\n",
    "    c = prints + 1\n",
    "    p = 1\n",
    "    W = torch.randn((tokenizer.vsize, tokenizer.vsize), requires_grad=True)\n",
    "    #print(c)\n",
    "    fig = plt.figure(figsize=(c*4, r*4))\n",
    "    losses = []\n",
    "    for k in range(passes):\n",
    "        loss = forward(W, xs, ys, learning_rate, tokenizer.vsize)\n",
    "        losses.append(loss.item())\n",
    "        #backward pass\n",
    "        W.grad = None\n",
    "        loss.backward() #will reverse fwd pass ops and update W.grad\n",
    "        \n",
    "        #update\n",
    "        W.data += -1 * W.grad\n",
    "        \n",
    "        if(k % s == 0):\n",
    "            fig.add_subplot(r, c, p).title.set_text('Pass: {passes}, Loss: {ploss:.4f}'.format(passes=k, ploss=loss.item()))\n",
    "            plt.imshow(W.detach().numpy())\n",
    "            #fig.add_subplot(r, c, c+p)\n",
    "            #plt.imshow(W.grad.detach().numpy())\n",
    "            p += 1\n",
    "    \n",
    "    fig.add_subplot(r, c, p).title.set_text('Pass: {passes}, Loss: {ploss:.4f}'.format(passes=k, ploss=loss.item()))\n",
    "    plt.imshow(W.detach().numpy())\n",
    "    #fig.add_subplot(r, c, c+p)\n",
    "    #plt.imshow(W.grad.detach().numpy())\n",
    "            \n",
    "    plt.show()\n",
    "    return W, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66667d0a-3028-4374-9c6f-aa83cc3ed016",
   "metadata": {},
   "source": [
    "#### Versuch zu Aufgabe 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b0dbc-bb4c-4e23-87a4-36d1ca092a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "steps = 4096\n",
    "\n",
    "(W_learned, losses) = learn(steps, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c7ec8-b12e-4f1f-aa7b-c06fcc53711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(W_learned.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57abd7a2-1d11-450d-bd95-a83a3be02c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d4631-d53e-4b5e-ad34-511c0308e07b",
   "metadata": {},
   "source": [
    "#### Aufgabe 4\n",
    "\n",
    "Führen sie die drei Zellen des Versuch oberhalb mit drei verschiedenen Werten für 'steps' durch: 512, 2048, 4096. Die Beiden Bilder obherhalb zeigen die Gewichte der Neuronen und den durchschnittlichen Fehler des Modells.\n",
    "\n",
    "##### 4 + 1 + 1 + 2 = 8 Punkte\n",
    "\n",
    "- F: Beschreiben sie, wie sich die beiden Bilder obenrhalb verändern wenn der Wert für Steps größer wird?\n",
    "- A:\n",
    "- F: An welches Bild aus der vorherigen Stunde erinnert Sie das letzte Bild mit 4096 steps?\n",
    "- A:\n",
    "- F: Wie gut ist das Modell gegenüber unserem Versuch letzte Stunde?\n",
    "- A:\n",
    "- F: Was müssten Sie tun um es noch besser zu machen?\n",
    "- A:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601be76-dc83-4b01-94e6-8538475aef45",
   "metadata": {},
   "source": [
    "### Finale\n",
    "\n",
    "Abschließend können wir aus dem neu trainierten Modell Texte erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8c12e-6fd7-4e0b-a3e6-cb1468c91b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = 32\n",
    "start = tokenizer.idx('<NL>')\n",
    "\n",
    "id_seq = generate(W, tokens, start)\n",
    "print(id_seq)\n",
    "print(tokenizer.decode(id_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032f318-4424-401a-b591-cb4510b10a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea7acb-7da8-485c-bc38-1c97def183bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
